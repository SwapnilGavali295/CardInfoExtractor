{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZtDyhLAVr5WI5qXMlcHSQzntSv3n_LGj","authorship_tag":"ABX9TyPVrbXwCuQZuRU5QU7nmGto"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Extracting Entities from Contact Cards**\n","The provided excel file had unstructured text in the 'parsedTxt' column, making it challenging to extract specific details such as names, phone numbers, emails, and other contact information.\n","\n","Initially, simple regular expressions (re) were used to extract information like names, phone numbers, emails, and addresses. However, the task of precisely identifying names was complicated due to various patterns and structures present in the data.To enhance name extraction, a list of top 10,000 English words was obtained from a reliable [source](https://www.mit.edu/~ecprice/wordlist.10000). This word list was utilized to filter out words that weren't commonly used in English, helping in distinguishing and filtering Indian names.\n","\n","Further exploration was carried out using Natural Language Processing (NLP) libraries such as NLTK, spaCy, and Flair for Named Entity Recognition (NER). Despite their use, the accuracy was limited since these models were primarily trained on English datasets, and Indian names or specific addresses might not align perfectly with their training data.\n","\n","Extraction of phone numbers, emails, and websites was relatively straightforward using regular expressions. However, extracting company names posed challenges due to the absence of a fixed pattern in the dataset. The Flair library was employed to identify 'organization' entities, but the results were not as accurate as expected.For job profiles, a keyword-based approach was used. A list of job-related keywords was employed, and regular expressions were utilized to filter and extract information that matched at least one word from this list."],"metadata":{"id":"7aAx4BKl13Wp"}},{"cell_type":"code","source":["# Import necessary libraries\n","import re  # Import the regular expression library for text processing\n","!pip install flair\n","import flair  # Import Flair for NLP tasks\n","import spacy  # Import Spacy for advanced NLP\n","import nltk  # Import NLTK for NLP operations\n","import pandas as pd  # Import Pandas for working with data\n","from nltk.stem import WordNetLemmatizer  # Import WordNetLemmatizer for word lemmatization\n","from flair.data import Sentence  # Import Sentence class from Flair for sentence-level processing\n","from flair.models import SequenceTagger  # Import SequenceTagger from Flair for sequence labeling\n","from nltk.tokenize import word_tokenize  # Import word_tokenize for word tokenization\n","from nltk.tag import pos_tag  # Import pos_tag for part-of-speech tagging\n","from nltk.chunk import ne_chunk  # Import ne_chunk for named entity chunking\n","import random # For generating random numbers\n"],"metadata":{"id":"ZOO-yJvYqCs-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae69a427-f997-4c4d-944a-3bb022612ea2","executionInfo":{"status":"ok","timestamp":1698499559323,"user_tz":-330,"elapsed":12719,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: flair in /usr/local/lib/python3.10/dist-packages (0.12.2)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n","Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1.0+cu118)\n","Requirement already satisfied: gensim>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.3.2)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.1)\n","Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.11)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n","Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.3)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\n","Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1.0)\n","Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.14)\n","Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.7)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from flair) (1.28.73)\n","Requirement already satisfied: transformers[sentencepiece]>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.34.1)\n","Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from flair) (0.3.4)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from flair) (2023.6.3)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from flair) (1.0.9)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.3)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from flair) (6.1.1)\n","Requirement already satisfied: janome in /usr/local/lib/python3.10/dist-packages (from flair) (0.5.0)\n","Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.4.0)\n","Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.17.3)\n","Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.5.3)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from flair) (10.1.0)\n","Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.10/dist-packages (from flair) (0.6.0)\n","Requirement already satisfied: pptree in /usr/local/lib/python3.10/dist-packages (from flair) (3.1)\n","Requirement already satisfied: pytorch-revgrad in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.0)\n","Requirement already satisfied: transformer-smaller-training-vocab>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from flair) (0.3.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (3.12.4)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (1.16.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (4.11.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (1.23.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (0.1.99)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (6.4.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2023.6.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (23.2)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (3.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.18.3)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (2.2.1)\n","Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.1.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (3.2.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.1.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.4.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.18.0->flair) (3.20.3)\n","Requirement already satisfied: botocore<1.32.0,>=1.31.73 in /usr/local/lib/python3.10/dist-packages (from boto3->flair) (1.31.73)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->flair) (1.0.1)\n","Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from boto3->flair) (0.7.0)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->flair) (0.2.8)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.73->boto3->flair) (2.0.7)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.24.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.5.0->flair) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2023.7.22)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[sentencepiece]>=4.18.0->flair) (5.9.5)\n"]}]},{"cell_type":"code","source":["# Downloading essential NLTK resources:\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkZNri9ft9mX","executionInfo":{"status":"ok","timestamp":1698499559323,"user_tz":-330,"elapsed":9,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"993478c2-c94b-4470-df08-4fad01e70e33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":138}]},{"cell_type":"code","source":["# Download the large English language model for spaCy\n","!python -m spacy download en_core_web_lg"],"metadata":{"id":"RUigcKSkwGl9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698499655686,"user_tz":-330,"elapsed":96368,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"68de8991-c908-4521-9df4-98fbc2f7f76e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-28 13:26:03.104970: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-28 13:26:03.105122: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-28 13:26:03.105263: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-10-28 13:26:07.478365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Collecting en-core-web-lg==3.6.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.6.0/en_core_web_lg-3.6.0-py3-none-any.whl (587.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m943.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.6.0) (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.1.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n"]}]},{"cell_type":"markdown","source":["#**English words and Job Title Recognition**"],"metadata":{"id":"eHRJ8H2dWCs7"}},{"cell_type":"code","source":["common_words = set()\n","# Load the list of top 10 thousand common words in english from 'top10k.txt' file\n","with open('top10k.txt', 'r') as file:\n","    for line in file:\n","        word = line.strip()  # Remove leading/trailing whitespace\n","        common_words.add(word)\n","common_jobs = set()\n","# Load the list of common words used for jobs in english from 'jobs.txt' file\n","with open('jobs.txt', 'r') as file:\n","    text = file.read()\n","    words = text.split()\n","# Iterate through the words and add them to the set\n","    for word in words:\n","        word=word.lower()\n","        common_jobs.add(word)\n","def is_english_word(word):\n","    lemmatizer = WordNetLemmatizer()\n","    word=word.lower()\n","    # Convert word to its base form\n","    wl = lemmatizer.lemmatize(word, pos=\"n\")\n","    # Check if the word is in the list of common words\n","    if wl in common_words:\n","        return True\n","    return False\n","def is_job(word):\n","    # Check if the word is in the list of common_jobs\n","    word=word.lower()\n","    if word in common_jobs:\n","        return True\n","    return False\n"],"metadata":{"id":"vl0lt5sQrkyH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#RE based functions to extract contact entity"],"metadata":{"id":"cdKKwoNTVurM"}},{"cell_type":"code","source":["# Function to extract Full name from text\n","def extract_name(text):\n","    # Define a regular expression pattern to match names\n","    name_pattern = r'(M(r|s|rs)\\.\\s)?[A-Z]([A-Z]+|[a-z]+)\\s[A-Z]\\w*\\s'\n","\n","    # Find all matches in the text\n","    matches = re.finditer(name_pattern, text)\n","\n","    # List to store matched names\n","    matched_names = []\n","\n","    # Iterate through the matches and store them in the list\n","    for match in matches:\n","        matched_names.append(match.group())\n","\n","    # Iterate through the matched names\n","    for entity in matched_names:\n","\n","        # Check if the entity has at least two words\n","        if entity and len(entity.split()) >= 2:\n","            flag = 0\n","            words = entity.split()\n","\n","            # Check each word in the entity\n","            for word in words:\n","                # Check if the word is an English word or if it's too short\n","                if is_english_word(word) or len(word) <= 2:\n","                    flag = 1\n","\n","            # If no problematic words were found, consider it a valid name\n","            if flag == 0:\n","                return entity\n","\n","\n","# Function to extract job titles from text\n","def extract_job(text):\n","    # Define a regular expression pattern to match job titles\n","    job_pattern = r'(M(r|s|rs)\\.\\s)?[A-Z]([A-Z]+|[a-z]+)\\s[A-Z]\\w*\\s'\n","\n","    # Find all matches in the text\n","    matches = re.finditer(job_pattern, text)\n","\n","    # List to store matched job titles\n","    matched_jobs = []\n","\n","    # Iterate through the matches and store them in the list\n","    for match in matches:\n","        matched_jobs.append(match.group())\n","\n","    # Iterate through the matched job titles\n","    for entity in matched_jobs:\n","        #print(entity)\n","\n","        flag = 0\n","        words = entity.split()\n","\n","        # Check each word in the entity\n","        for word in words:\n","            # If a word does not match the criteria for a job title, increment the flag\n","            if not is_job(word):\n","                flag += 1\n","\n","        # If there is at most one non-job title word, consider it a valid job title\n","        if flag <= 1:\n","            return entity\n","# Function to extract phone numbers from text\n","def extract_numbers(text):\n","    # Define a regular expression pattern to match phone numbers\n","    number_pattern = r'(\\+91[\\-\\s]?)?\\d{5}(\\s|\\s{2}|-)?\\d{5}'\n","\n","    # List to store matched phone numbers\n","    matched_numbers = []\n","\n","    # Find all matches in the text\n","    matches = re.finditer(number_pattern, text)\n","\n","    # Iterate through the matches and store them in the list\n","    for match in matches:\n","        matched_numbers.append(match.group())\n","        #print(match)\n","\n","    return matched_numbers\n","\n","# Function to extract email addresses from text\n","def extract_emails(text):\n","    # Define a regular expression pattern to match email addresses\n","    email_pattern = r'[a-zA-Z0-9.-]+(\\s)?@[a-zA-Z0-9-\\s]+(\\.|,)?(com|net|org|in|edu|pe|ai|money|tech|one|ailen|org.in|co.in)'\n","    #r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b'\n","    #r'[a-zA-Z0-9.-]+(\\s)?@[a-zA-Z0-9-\\s]+(\\.|,)?(com|net|org|in|edu|pe|ai|money|tech|one|ailen|org.in|co.in)'\n","\n","    # List to store matched email addresses\n","    matched_emails = []\n","\n","    # Find all matches in the text\n","    matches = re.finditer(email_pattern, text)\n","\n","    # Iterate through the matches and store them in the list\n","    for match in matches:\n","        matched_emails.append(match.group())\n","        #print(match)\n","\n","    return matched_emails\n","\n","# Function to extract website URLs from text\n","def extract_website(text):\n","    # Define a regular expression pattern to match website URLs\n","    url_pattern = r'\\s(https?://)?(www\\.|WWW\\.|wwW\\.|Www\\.)?(\\w+|[a-zA-Z-]+)\\.(\\s)?(com|net|org|in|pe|edu|ai|money|tech|one|ailen|org.in|co.in)'\n","\n","    # List to store matched website URLs\n","    matched_urls = []\n","\n","    # Find all matches in the text\n","    matches = re.finditer(url_pattern, text)\n","\n","    # Iterate through the matches and store them in the list\n","    for match in matches:\n","        matched_urls.append(match.group())\n","\n","    return matched_urls\n","\n","# Function to extract addresses from text\n","def extract_address(text):\n","    # Define regular expressions to match different parts of an address\n","    address_start = re.compile(r'\\s[A-Za-z\\.0-9]+?\\s\\w+\\,')\n","    address_end = re.compile(r'\\,(\\s|\\s{2}|\\s{3})[A-Za-z\\.0-9]+\\s([A-Za-z]+)?(\\W+)')\n","    pincode = re.compile(r'\\s\\d{6}\\s')\n","\n","    matched_address = []\n","\n","    # Find the start of the address\n","    start_matches = address_start.finditer(text)\n","    for match in start_matches:\n","        matched_address.append(match.group())\n","        # Only consider the first match\n","        break\n","\n","    # Find the middle part of the address\n","    middle_address = re.compile(r\"(?<=\\,)[^\\,]+(?=\\,)\")\n","    middle_matches = middle_address.finditer(text)\n","    for match in middle_matches:\n","        matched_address.append(match.group())\n","\n","    # Find the end of the address\n","    end_matches = address_end.finditer(text)\n","    flag = 0\n","    for match in end_matches:\n","        flag = 1\n","        end_match = match.group()\n","\n","    # If an end match was found, add it to the address\n","    if flag == 1:\n","        matched_address.append(end_match)\n","\n","    # Find the pincode\n","    pincode_matches = pincode.finditer(text)\n","    for match in pincode_matches:\n","        matched_address.append(match.group())\n","\n","    # Concatenate the matched address parts\n","    address = ''\n","    for word in matched_address:\n","        address += word\n","\n","    return address\n"],"metadata":{"id":"YBQyg0CyQ_Q1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**NER(Name entity recognition) based functions to extract contact entity**"],"metadata":{"id":"vZ9EXr3Gy64z"}},{"cell_type":"code","source":["def extractfromspacy(text):\n","    # Load the English language model\n","    nlp = spacy.load(\"en_core_web_lg\")\n","\n","    # Process the text with spaCy\n","    doc = nlp(text)\n","\n","    # Iterate through named entities in the text\n","    for ent in doc.ents:\n","        # Print the entity text and its label\n","        print(ent.text, \"|\", ent.label_)\n","\n","        # Check if the entity is an organization (label 'ORG') and has a length of 10 characters or more\n","        if len(ent.text) >= 10 and ent.label_ == 'ORG':\n","            return ent.text\n","\n","def extractfromnltk2(text):\n","    tokens = word_tokenize(text)\n","    tagged = pos_tag(tokens)\n","    tree = ne_chunk(tagged)\n","\n","    # Extract named entities\n","    named_entities = []\n","\n","    for subtree in tree:\n","        if isinstance(subtree, nltk.Tree):\n","            entity = \" \".join([word for word, tag in subtree.leaves()])\n","            entity_label = subtree.label()\n","            named_entities.append((entity, entity_label))\n","\n","    # Print all named entities\n","    for entity, label in named_entities:\n","        print(f\"Entity: {entity}, Label: {label}\")\n","    for entity, label in named_entities:\n","        if \"ORGANIZATION\" in label and len(entity.split()) >= 2 :\n","            flag=0;\n","            words = entity.split()\n","            for word in words:\n","                if is_english_word(word):\n","                    flag=1\n","            if(flag==0):\n","                return entity\n","\n","    # If no person entity is found, return None\n","    return None\n","\n","# Load the NER (Named Entity Recognition) model\n","tagger = SequenceTagger.load(\"ner\")\n","# Function to extract organizations from text using Flair\n","def extractfromflair(text):\n","\n","\n","    # Create a Flair Sentence object with the input text\n","    sentence = Sentence(text)\n","\n","    # Use the NER model to predict named entities in the sentence\n","    tagger.predict(sentence)\n","\n","    #named_entities = []\n","\n","    # Iterate through the named entities recognized by Flair\n","    for entity in sentence.get_spans(\"ner\"):\n","        #named_entities.append((entity.text, entity.tag))\n","        # Print the recognized entity and its tag (optional)\n","        # print(f\"Entity: '{entity.text}' ({entity.tag})\")\n","\n","        # Check if the entity is an organization (tag 'ORG') and has a length of 10 characters or more\n","        if len(entity.text) >= 10 and entity.tag == 'ORG':\n","            return entity.text\n","\n","    # If no ORG entity is found, return None\n","    return None\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qOH_14T0r-Lf","executionInfo":{"status":"ok","timestamp":1698499662029,"user_tz":-330,"elapsed":6350,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"bc626db7-903d-4833-d1f8-9e7aad374c6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-28 13:27:39,832 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"]}]},{"cell_type":"code","source":["df=pd.read_excel('MyContacts(1).xlsx') # Read data from the Excel file 'MyContacts(1).xlsx' into a Pandas DataFrame"],"metadata":{"id":"pUrH1ktZsD5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text=df['parsedTxt'][random.randint(0, 170)] #Sample text\n","text = text.replace('\\n','  ') #modifying text for RE\n","text = ' ' + text + ' '\n","print(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVx3dT2csUL2","executionInfo":{"status":"ok","timestamp":1698500475852,"user_tz":-330,"elapsed":607,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"ad938893-64ec-45f7-c8d3-d1f444d660dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Senior Associate UPI Product Development  Viraj Shah  National Payments Corporation of india  3rd Floor 302. Raheja Titanium,  Off. Western Express Highway,  Goregaon (E), Mumbai - 400 063  T: +919082054231  Email: viraj.shah@npci.org.in  Website: wwW.npci.org.in \n"]}]},{"cell_type":"code","source":["# Extract name (using RE and English words)\n","extract_name(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"_DQU9ObOscMp","executionInfo":{"status":"ok","timestamp":1698500479441,"user_tz":-330,"elapsed":680,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"0cf95567-a313-467f-c57b-23b853c760e9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Viraj Shah '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":169}]},{"cell_type":"code","source":["# Extract job title (using RE and common job related words)\n","extract_job(text)"],"metadata":{"id":"g18EmkvGuGZR","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1698500481061,"user_tz":-330,"elapsed":5,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"331da6b0-eff6-4a48-e2ab-835a58917063"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Senior Associate '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":170}]},{"cell_type":"code","source":["# Extract addresse (using purely RE)\n","extract_address(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"JoMiVnjYvXtP","executionInfo":{"status":"ok","timestamp":1698500484136,"user_tz":-330,"elapsed":596,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"33ce2c0c-56ad-4bab-f660-8e1665118102"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Raheja Titanium,  Off. Western Express Highway  Goregaon (E), Mumbai - '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":171}]},{"cell_type":"code","source":[" # Extract phone numbers (using purely RE)\n","extract_numbers(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxayc7pQvduB","executionInfo":{"status":"ok","timestamp":1698500486328,"user_tz":-330,"elapsed":492,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"b571369b-8a4f-4549-edec-87800100b918"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['+919082054231']"]},"metadata":{},"execution_count":172}]},{"cell_type":"code","source":["# Extract website URL (using purely RE)\n","extract_website(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzOF7udovTGs","executionInfo":{"status":"ok","timestamp":1698500488212,"user_tz":-330,"elapsed":9,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"6cbfdb35-1bb8-41f0-c083-004f15ebb2a0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' wwW.npci.org']"]},"metadata":{},"execution_count":173}]},{"cell_type":"code","source":["# Extract email addresses (using purely RE)\n","extract_emails(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qq8-bLtcvoaA","executionInfo":{"status":"ok","timestamp":1698500490760,"user_tz":-330,"elapsed":656,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"1f87b7de-e814-4d44-8244-fa7ae44486ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['viraj.shah@npci.org']"]},"metadata":{},"execution_count":174}]},{"cell_type":"code","source":["# Extract company name (label ORG) using Flair (using ner)\n","extractfromflair(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"f_Jni_Obu0iK","executionInfo":{"status":"ok","timestamp":1698500499825,"user_tz":-330,"elapsed":7171,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"4ae69c36-dd97-41ed-da66-d5f510ad826b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Viraj Shah  National Payments Corporation of india'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":175}]},{"cell_type":"code","source":["# Extract company name (label ORG) using spacy (using ner)\n","extractfromspacy(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1698500513233,"user_tz":-330,"elapsed":9916,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"7a5b0c9e-7aaf-4ae2-f4d7-692712bc58cb","id":"9gMCWWomwYGX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Associate UPI Product Development | ORG\n"]},{"output_type":"execute_result","data":{"text/plain":["'Associate UPI Product Development'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":176}]},{"cell_type":"code","source":["# Extract entities using Flair (using ner)\n","extractfromnltk2(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698500515773,"user_tz":-330,"elapsed":616,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"f28ebe59-b3be-4991-af8a-d1200d5942de","id":"r7Kvp8mlwYgM"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Entity: Associate, Label: ORGANIZATION\n","Entity: Shah National Payments Corporation, Label: PERSON\n","Entity: Raheja Titanium, Label: PERSON\n","Entity: Off, Label: PERSON\n","Entity: Western Express Highway, Label: PERSON\n","Entity: Goregaon, Label: GPE\n","Entity: Mumbai, Label: GPE\n","Entity: Website, Label: PERSON\n"]}]},{"cell_type":"code","source":["#going through whole dataset\n","for index, row in df.iterrows():\n","    # Check if the 'parsedTxt' column is not empty\n","    if pd.notna(row['parsedTxt']):\n","        text = row['parsedTxt']\n","\n","    # Text preprocessing\n","    text2 = text.replace('\\n', '  ')\n","    text2 = ' ' + text2 + ' '\n","\n","    # Extract name (using RE and English words)\n","    name = extract_name(text2)\n","    if name:\n","        df.at[index, 'fullname'] = name\n","        text2 = text2.replace(name, ' ') #removing found entity for imporving further accuracy\n","\n","    # Extract phone numbers (using purely RE)\n","    number = extract_numbers(text2)\n","    if len(number) == 2:\n","        text2 = text2.replace(number[0], ' ')\n","        text2 = text2.replace(number[1], ' ')\n","        df.at[index, 'phone'] = number[0]\n","        df.at[index, 'phone_2'] = number[1]\n","    elif len(number) == 1:\n","        text2 = text2.replace(number[0], ' ')\n","        df.at[index, 'phone'] = number[0]\n","\n","    # Extract email addresses (using purely RE)\n","    email = extract_emails(text2)\n","    if len(email) == 2:\n","        df.at[index, 'email'] = email[0]\n","        text2 = text2.replace(email[0], ' ')\n","        df.at[index, 'email_2'] = email[1]\n","        text2 = text2.replace(email[1], ' ')\n","    elif len(email) == 1:\n","        df.at[index, 'email'] = email[0]\n","        text2 = text2.replace(email[0], ' ')\n","\n","    # Extract website URL (using purely RE)\n","    website = extract_website(text2)\n","    if website:\n","        df.at[index, 'website'] = website[0]\n","        text2 = text2.replace(website[0], ' ')\n","\n","    # Extract address (using purely RE)\n","    address = extract_address(text2)\n","    if address:\n","        df.at[index, 'address'] = address\n","\n","    # Extract job title (using RE and common job related words)\n","    job_title = extract_job(text2)\n","    if job_title:\n","        df.at[index, 'job_title'] = job_title\n","\n","    # Extract company name using Flair (using ner)\n","    company_name = extractfromflair(text)\n","    if company_name:\n","        df.at[index, 'company'] = company_name\n"],"metadata":{"id":"Uks9n_8Qv1Vo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the DataFrame to an Excel file\n","df.to_excel(\"MyContacts2.xlsx\",index=False)"],"metadata":{"id":"x8nzx3KWv48j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"Mq4UisFlUNxG","executionInfo":{"status":"ok","timestamp":1698500335041,"user_tz":-330,"elapsed":13,"user":{"displayName":"Swapnil Gavali","userId":"15032919853709386157"}},"outputId":"42093b6e-849b-4fb5-d76d-a40bd7933aa0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           parsedTxt             fullname  \\\n","0  Making Payment Simpter\\nSambhav Pay\\n+91-70654...   Mrs. Sapna Raghav    \n","1  Making Payment Simpier\\nSambhav Pay\\n+91-88824...  Mr. Jayant Mallick    \n","2  Vaibhavi Kamath\\nExecutive Assistant to CEO\\nK...     Vaibhavi Kamath    \n","3  aytring\\nDebal Chakraborty\\nCo-Founder\\nOFfice...   Debal Chakraborty    \n","4  dheerajafinarkein.com\\nG +91 83296 07320\\nChie...       Dheeraj Kumar    \n","\n","          company             job_title  \\\n","0     Udyog Vihar        BUSINESS HEAD    \n","1             NaN                   NaN   \n","2  KNIGHT FINTECH  Executive Assistant    \n","3             NaN                   NaN   \n","4             NaN     Chief Technology    \n","\n","                                             address            phone phone_2  \\\n","0   Udyog Vihar, Haryana  B21 Phase-5 Udyog Vihar...   +91-7065483258     NaN   \n","1   Udyog Vihar, Haryana  B21 Phase-5 Udyog Vihar...   +91-8882484147     NaN   \n","2                                                NaN    +919136706988     NaN   \n","3      MM Towers    Sector-18 Gurgaon, MM Towers       +91 9711192256     NaN   \n","4                                                NaN  +91 83296 07320     NaN   \n","\n","                        email email_2                 website  \n","0          ops@sambhavpay.com     NaN      www.sambhavpay.com  \n","1       jayant@sambhavpay.com     NaN      www.sambhavpay.com  \n","2  vaibhavi@knightfintech.com     NaN   www.knightfintech.com  \n","3           debal@paytringcom     NaN        www.paytring.com  \n","4                         NaN     NaN   dheerajafinarkein.com  "],"text/html":["\n","  <div id=\"df-9f792446-58fd-4f3c-a12e-dd8a7b1818de\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>parsedTxt</th>\n","      <th>fullname</th>\n","      <th>company</th>\n","      <th>job_title</th>\n","      <th>address</th>\n","      <th>phone</th>\n","      <th>phone_2</th>\n","      <th>email</th>\n","      <th>email_2</th>\n","      <th>website</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Making Payment Simpter\\nSambhav Pay\\n+91-70654...</td>\n","      <td>Mrs. Sapna Raghav</td>\n","      <td>Udyog Vihar</td>\n","      <td>BUSINESS HEAD</td>\n","      <td>Udyog Vihar, Haryana  B21 Phase-5 Udyog Vihar...</td>\n","      <td>+91-7065483258</td>\n","      <td>NaN</td>\n","      <td>ops@sambhavpay.com</td>\n","      <td>NaN</td>\n","      <td>www.sambhavpay.com</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Making Payment Simpier\\nSambhav Pay\\n+91-88824...</td>\n","      <td>Mr. Jayant Mallick</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Udyog Vihar, Haryana  B21 Phase-5 Udyog Vihar...</td>\n","      <td>+91-8882484147</td>\n","      <td>NaN</td>\n","      <td>jayant@sambhavpay.com</td>\n","      <td>NaN</td>\n","      <td>www.sambhavpay.com</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Vaibhavi Kamath\\nExecutive Assistant to CEO\\nK...</td>\n","      <td>Vaibhavi Kamath</td>\n","      <td>KNIGHT FINTECH</td>\n","      <td>Executive Assistant</td>\n","      <td>NaN</td>\n","      <td>+919136706988</td>\n","      <td>NaN</td>\n","      <td>vaibhavi@knightfintech.com</td>\n","      <td>NaN</td>\n","      <td>www.knightfintech.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>aytring\\nDebal Chakraborty\\nCo-Founder\\nOFfice...</td>\n","      <td>Debal Chakraborty</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>MM Towers    Sector-18 Gurgaon, MM Towers</td>\n","      <td>+91 9711192256</td>\n","      <td>NaN</td>\n","      <td>debal@paytringcom</td>\n","      <td>NaN</td>\n","      <td>www.paytring.com</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dheerajafinarkein.com\\nG +91 83296 07320\\nChie...</td>\n","      <td>Dheeraj Kumar</td>\n","      <td>NaN</td>\n","      <td>Chief Technology</td>\n","      <td>NaN</td>\n","      <td>+91 83296 07320</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>dheerajafinarkein.com</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f792446-58fd-4f3c-a12e-dd8a7b1818de')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9f792446-58fd-4f3c-a12e-dd8a7b1818de button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9f792446-58fd-4f3c-a12e-dd8a7b1818de');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ff7519ae-f4d0-4297-b3b1-adeeead16554\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff7519ae-f4d0-4297-b3b1-adeeead16554')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ff7519ae-f4d0-4297-b3b1-adeeead16554 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":156}]},{"cell_type":"markdown","source":["#**Summary**\n","The process involved a series of attempts using both regular expressions and NLP-based techniques to extract specific entities from the unstructured text. While some information like phone numbers, emails, and websites could be extracted fairly accurately from RE, challenges were encountered, especially in identifying names, company names, and job titles due to the varied nature of the data. Notably, Named Entity Recognition using **Flair** was utilized specifically for extracting **company names** due to its relatively higher accuracy compared to Spacy and NLTK NER models. However, its performance was below average in accurately identifying entities in the provided text."],"metadata":{"id":"-A3CJVh-D_V_"}}]}